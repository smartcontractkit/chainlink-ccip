version: v2beta1
name: chainlink

vars:
  DEVSPACE_ENV_FILE: .env

  # The list of default ENV Vars for CRIB, you can override any of them in the .env file
  # The image that will be used for the Chainlink nodes.
  DEVSPACE_IMAGE:
    source: env
    default: "323150190480.dkr.ecr.us-west-2.amazonaws.com/chainlink-devspace"
  # This is a comma separated list of CIDR blocks that will be allowed to access the ingress.
  DEVSPACE_INGRESS_CIDRS:
    source: env
    default: "0.0.0.0/0"
  # This is the base domain in AWS Route 53 that our ingress subdomains will use.
  DEVSPACE_INGRESS_BASE_DOMAIN:
    source: env
    default: "main.stage.cldev.sh"
  # This is the ARN of the AWS ACM certificate that will be used for the ingress.
  DEVSPACE_INGRESS_CERT_ARN:
    source: env
    default: "arn:aws:acm:us-west-2:323150190480:certificate/edd19542-7c7c-42dc-ba00-507c4b962ed3"
  # Time to wait for pods to be in `Ready` condition
  DEVSPACE_K8S_POD_WAIT_TIMEOUT:
    source: env
    default: 1200s
  # Helm repo URI for the crib-ccip helm chart
  CCIP_HELM_CHART_URI:
    source: env
    default: "oci://804282218731.dkr.ecr.us-west-2.amazonaws.com/infra-charts/crib-ccip"

  # Env Vars Required for ccip-scripts based contracts and jobs deployment
  # Image URI required for deploying CCIP Contracts and Jobs
  DEVSPACE_CCIP_SCRIPTS_IMAGE:
    source: env
    default: "804282218731.dkr.ecr.us-west-2.amazonaws.com/ccip-scripts:latest"
  # AWS Role ARN required for uploading deploy job output to s3
  DEVSPACE_CCIP_SCRIPTS_OIDC_ROLE_ARN:
    source: env
    default: "arn:aws:iam::323150190480:role/ccip-scripts-deployer-upload"
  # AWS S3 bucket name required for uploading deploy job output to s3
  DEVSPACE_CCIP_SCRIPTS_OUTPUT_BUCKET_NAME:
    source: env
    default: "cl-stage-ccip-scripts-deploy-output"

  # Env vars required for Atlas Monitoring
  ATLAS_NETWORK_HELM_CHART_URI:
    source: env
    default: "oci://804282218731.dkr.ecr.us-west-2.amazonaws.com/infra-charts/crib-atlas-core"
  ATLAS_INFRA_HELM_CHART_URI:
    source: env
    default: "oci://804282218731.dkr.ecr.us-west-2.amazonaws.com/infra-charts/crib-atlas-infra"
  ## CHANGE-ME PATH for your infra charts (change to your infra-charts dir)
  MONITORING_INFRA_CHARTS_PATH:
    source: env
    default: "${CHAINLINK_CODE_DIR}/infra-charts"
  ## Paths for all the required elements.
  MONITORING_INFRA_PATH:
    source: env
    default: "${MONITORING_INFRA_CHARTS_PATH}/crib-atlas-infra"
  MONITORING_NETWORK_PATH:
    source: env
    default: "${MONITORING_INFRA_CHARTS_PATH}/crib-atlas-core/"
  MONITORING_SCRIPT:
    source: env
    default: "./atlas/init"
  MONITORING_NETWORK_2_VALUES_PATH:
    source: env
    default: "${MONITORING_SCRIPT}/output/values-network-2.yaml"
  MONITORING_NETWORK_1_VALUES_PATH:
    source: env
    default: "${MONITORING_SCRIPT}/output/values-network-1.yaml"

pipelines:
  deploy:
    flags:
      - name: override-image-tag
        short: o
        type: string
        description: "If specified, the specified tag will be used instead of building a new image"

    run: |-
      tagOverride=$(get_flag "override-image-tag")
      run_dependencies --all

      if [[ -n "${tagOverride}" ]]; then
        image=${DEVSPACE_IMAGE}:${tagOverride}
        echo "Using user provided image: $image"

        args=""
        for i in {0..5}; do
          args+="--set=helm.values.crib-chainlink-cluster.chainlink.nodes[$i].image=$image "
        done

        create_deployments app $args
      else
        build_images --all
        create_deployments app
      fi

      run_pipelines atlas

      kubectl label namespace/${DEVSPACE_NAMESPACE} network=crib > /dev/null 2>&1 || true

  atlas:
    run: |-
      run_pipelines atlas-infra
      run_pipelines atlas-network-1 atlas-network-2
  atlas-infra:
    run: |-
      create_deployments atlas-infra
  atlas-network-1:
    run: |-
      cd ${MONITORING_SCRIPT}
      go run main.go config.yaml  values-network-1.yaml
      cd ../..
      create_deployments atlas-network-1
  atlas-network-2:
    run: |-
      cd ${MONITORING_SCRIPT}
      go run main.go  config-2.yaml  values-network-2.yaml
      cd ../..
      create_deployments atlas-network-2

  atlas-dev:
    run: |-
      run_pipelines atlas-infra-dev
      run_pipelines atlas-network-1-dev atlas-network-2-dev
  atlas-infra-dev:
    run: |-
      create_deployments atlas-infra-dev
  atlas-network-1-dev:
    run: |-
      cd ${MONITORING_SCRIPT}
      go run main.go config.yaml  values-network-1.yaml
      cd ../..
      create_deployments atlas-network-1-dev
  atlas-network-2-dev:
    run: |-
      cd ${MONITORING_SCRIPT}
      go run main.go  config-2.yaml  values-network-2.yaml
      cd ../..
      create_deployments atlas-network-2-dev

  purge:
    run: |-
      kubectl delete ns ${DEVSPACE_NAMESPACE}

commands:
  ingress-hosts:
    command: |-
      kubectl get ingress -n ${DEVSPACE_NAMESPACE} -o=jsonpath="{range .items[*].spec.rules[*]}{'https://'}{.host}{'\n'}{end}"
    description: List Kubernetes ingress hostnames in the namespace.
  connect:
    command: sudo kubefwd svc -n $1
    description: Expose Kubernetes services for local development.
  ttl:
    command: ./../scripts/label_namespace.sh $1 --overwrite
    description: Configure TTL for devspace resource cleanup. Default is 72h.
  workload:
    command: cd ../integration-tests/load/ocr && go test -v -run TestOCRLoad || cd -
    description: Run workload
  dashboard-deploy:
    command: go run dashboard/cmd/deploy.go
    description: Deploy dashboards
  dashboard-test:
    command: cd dashboard/tests && npx playwright test || cd -
    description: Run tests
  get_test_input:
    command: aws s3 cp s3://${DEVSPACE_CCIP_SCRIPTS_OUTPUT_BUCKET_NAME}/${DEVSPACE_NAMESPACE}-testInput.toml override.toml
    description: Download the testInput.toml file from the S3 bucket
  man:
    command: ../scripts/man.sh $1
    description: Display man pages

images:
  app:
    image: ${DEVSPACE_IMAGE}
    tags:
      - ${devspace.namespace}-${devspace.timestamp}
    custom:
      skipImageArg: true
      command: |-
        GIT_ROOT=$CHAINLINK_CODE_DIR/ccip
        cd $GIT_ROOT

        image=${runtime.images.app}
        MACOS_SDK_DIR=$(pwd)/tools/bin/MacOSX12.3.sdk IMAGE=$image ./tools/bin/goreleaser_wrapper release --snapshot --clean --config .goreleaser.devspace.yaml
        docker push $image
hooks:
  - command: ../scripts/before_deploy_checks.sh
    events: ["before:deploy:app"]
  - command: ./scripts/check_env_vars.sh
    events: ["before:deploy:app"]
  - wait:
      running: true
      terminatedWithCode: 0
      timeout: 600
    container:
      labelSelector:
        # vars don't work here, = releaseName
        release: "app"
    events: ["after:deploy:app"]

  # Check that the ingress was created successfully, and print ingress hostnames.
  - name: "ingress-check-hook"
    command: ./../scripts/ingress_check.sh
    args: ["app"] # Ingress name.
    events: ["after:deploy:app"]

  # Check that the namespace cleanup label is set successfully.
  - name: "label-namespace-hook"
    command: ./../scripts/label_namespace.sh
    args: ["${NS_TTL}"]
    events: ["after:deploy:app", "error:deploy:*"]

  # Prints man pages about available commands
  - command: ../scripts/man.sh
    events: ["after:deploy:app"]

# This is a list of `deployments` that DevSpace can create for this project
deployments:
  app:
    updateImageTags: false
    namespace: ${DEVSPACE_NAMESPACE}
    helm:
      upgradeArgs: ["--timeout", "10m"]
      releaseName: "app"
      chart:
        name: ${CCIP_HELM_CHART_URI}
        version: "1.x"
      # for simplicity, we define all the values here
      # they can be defined the same way in values.yml
      # devspace merges these "values" with the "values.yaml" before deploy
      values:
        podSecurityContext:
          fsGroup: 999

        crib-chainlink-cluster:
          chainlink:
            global:
              overridesToml: |-
                [Feature]
                LogPoller = true
                CCIP = true

                [Log]
                Level = 'debug'
                JSONConsole = true

                [Log.File]
                MaxSize = '0b'

                [WebServer]
                AllowOrigins = '*'
                HTTPPort = 6688
                SecureCookies = false
                HTTPWriteTimeout = '1m'

                [WebServer.RateLimit]
                Authenticated = 2000
                Unauthenticated = 1000

                [WebServer.TLS]
                HTTPSPort = 0

                [Database]
                MaxIdleConns = 50
                MaxOpenConns = 50
                MigrateOnStartup = true

                [OCR2]
                Enabled = true
                DefaultTransactionQueueDepth = 0

                [OCR]
                Enabled = false
                DefaultTransactionQueueDepth = 0

                [P2P]
                [P2P.V2]
                Enabled = true
                ListenAddresses = ['0.0.0.0:6690']
                AnnounceAddresses = ['0.0.0.0:6690']
                DeltaDial = '500ms'
                DeltaReconcile = '5s'
            securityContext:
              capabilities:
                drop:
                  - ALL
              readOnlyRootFilesystem: false
              runAsNonRoot: true
              runAsUser: 14933
              runAsGroup: 999
            web_port: 6688
            p2p_port: 6690
            # extraEnvVars:
            # "CL_MEDIAN_CMD": "chainlink-feeds"
            nodes:
              node1:
                image: ${runtime.images.app}
                # default resources are 300m/1Gi
                # first node need more resources to build faster inside container
                # at least 2Gi of memory is required otherwise build will fail (OOM)
                resources:
                  requests:
                    cpu: 2000m
                    memory: 2048Mi
                  limits:
                    cpu: 2000m
                    memory: 2048Mi
                # override default config per node
                # for example, use OCRv2 P2P setup, the whole config
                #      toml: |
                #        RootDir = './clroot'
                #        [Log]
                #        JSONConsole = true
                #        Level = 'debug'
                #        [WebServer]
                #        AllowOrigins = '*'
                #        SecureCookies = false
                #        SessionTimeout = '999h0m0s'
                #        [OCR2]
                #        Enabled = true
                #        [P2P]
                #        [P2P.V2]
                #        Enabled = false
                #        AnnounceAddresses = []
                #        DefaultBootstrappers = []
                #        DeltaDial = '15s'
                #        DeltaReconcile = '1m0s'
                #        ListenAddresses = []
                #        [[EVM]]
                #        ChainID = '1337'
                #        MinContractPayment = '0'
                #        [[EVM.Nodes]]
                #        Name = 'node-0'
                #        WSURL = 'ws://geth:8546'
                #        HTTPURL = 'http://geth:8544'
                #        [WebServer.TLS]
                #        HTTPSPort = 0
                # or use overridesToml to override some part of configuration
                # overridesToml: |
                # Enable Tracing
                #   [Tracing]
                #   Enabled = true
                #   SamplingRatio = 1.0
                #   CollectorTarget = 'app-opentelemetry-collector:4317'
                #   TLSCertPath = ''
                #   Mode = 'unencrypted'
              node2:
                image: ${runtime.images.app}
              node3:
                image: ${runtime.images.app}
              node4:
                image: ${runtime.images.app}
              node5:
                image: ${runtime.images.app}

          # each CL node have a dedicated PostgreSQL 11.15
          # use StatefulSet by setting:
          #
          # stateful: true
          # capacity 10Gi
          #
          # if you are running long tests
          db:
            securityContext:
              capabilities:
                drop:
                  - ALL
              readOnlyRootFilesystem: false
              runAsNonRoot: true
              runAsUser: 999
              runAsGroup: 999
            stateful: false
            resources:
              requests:
                cpu: 1
                memory: 1024Mi
              limits:
                cpu: 1
                memory: 1024Mi
          # default cluster shipped with latest Geth ( dev mode by default )
          geth:
            securityContext:
              capabilities:
                drop:
                  - ALL
              readOnlyRootFilesystem: false
              runAsNonRoot: true
              runAsUser: 999
              runAsGroup: 999
            version: v1.12.0
            wsRpcPort: 8546
            httpRpcPort: 8544
            chains:
              - networkId: 1337
                customEVMConfigToml: |
                  [EVM.GasEstimator]
                  PriceMax = '200 gwei'
                  LimitDefault = 6000000
                  FeeCapDefault = '200 gwei'
              - networkId: 2337
                customEVMConfigToml: |
                  [EVM.GasEstimator]
                  PriceMax = '200 gwei'
                  LimitDefault = 6000000
                  FeeCapDefault = '200 gwei'
            blocktime: 1
            resources:
              requests:
                cpu: 1
                memory: 1024Mi
              limits:
                cpu: 1
                memory: 1024Mi
          # mockserver is https://www.mock-server.com/where/kubernetes.html
          # used to stub External Adapters
          mockserver:
            #  image: "mockserver/mockserver"
            #  version: "mockserver-5.15.0"
            securityContext:
              capabilities:
                drop:
                  - ALL
              readOnlyRootFilesystem: false
              runAsNonRoot: true
              runAsUser: 999
              runAsGroup: 999
            enabled: true
            releasenameOverride: mockserver
            app:
              runAsUser: 999
              readOnlyRootFilesystem: false
            port: 1080
            resources:
              requests:
                cpu: 1
                memory: 1024Mi
              limits:
                cpu: 1
                memory: 1024Mi
          # monitoring.coreos.com/v1 PodMonitor for each node
          prometheusMonitor: true

          # These ingresses create AWS ALB resources and Route 53 Records.
          ingress:
            enabled: true
            baseDomain: ${DEVSPACE_INGRESS_BASE_DOMAIN}
            annotation_certificate_arn: ${DEVSPACE_INGRESS_CERT_ARN}
            annotation_group_name: ${DEVSPACE_NAMESPACE}
            hosts:
              - host: ${DEVSPACE_NAMESPACE}-node1.${DEVSPACE_INGRESS_BASE_DOMAIN}
                http:
                  paths:
                    - path: /
                      backend:
                        service:
                          name: app-node1
                          port:
                            number: 6688
              - host: ${DEVSPACE_NAMESPACE}-node2.${DEVSPACE_INGRESS_BASE_DOMAIN}
                http:
                  paths:
                    - path: /
                      backend:
                        service:
                          name: app-node2
                          port:
                            number: 6688
              - host: ${DEVSPACE_NAMESPACE}-node3.${DEVSPACE_INGRESS_BASE_DOMAIN}
                http:
                  paths:
                    - path: /
                      backend:
                        service:
                          name: app-node3
                          port:
                            number: 6688
              - host: ${DEVSPACE_NAMESPACE}-node4.${DEVSPACE_INGRESS_BASE_DOMAIN}
                http:
                  paths:
                    - path: /
                      backend:
                        service:
                          name: app-node4
                          port:
                            number: 6688
              - host: ${DEVSPACE_NAMESPACE}-node5.${DEVSPACE_INGRESS_BASE_DOMAIN}
                http:
                  paths:
                    - path: /
                      backend:
                        service:
                          name: app-node5
                          port:
                            number: 6688
              - host: ${DEVSPACE_NAMESPACE}-geth-1337-http.${DEVSPACE_INGRESS_BASE_DOMAIN}
                http:
                  paths:
                    - path: /
                      backend:
                        service:
                          name: geth-1337
                          port:
                            number: 8544
              - host: ${DEVSPACE_NAMESPACE}-geth-1337-ws.${DEVSPACE_INGRESS_BASE_DOMAIN}
                http:
                  paths:
                    - path: /
                      backend:
                        service:
                          name: geth-1337
                          port:
                            number: 8546
              - host: ${DEVSPACE_NAMESPACE}-geth-2337-http.${DEVSPACE_INGRESS_BASE_DOMAIN}
                http:
                  paths:
                    - path: /
                      backend:
                        service:
                          name: geth-2337
                          port:
                            number: 8544
              - host: ${DEVSPACE_NAMESPACE}-geth-2337-ws.${DEVSPACE_INGRESS_BASE_DOMAIN}
                http:
                  paths:
                    - path: /
                      backend:
                        service:
                          name: geth-2337
                          port:
                            number: 8546
              - host: ${DEVSPACE_NAMESPACE}-mockserver.${DEVSPACE_INGRESS_BASE_DOMAIN}
                http:
                  paths:
                    - path: /
                      backend:
                        service:
                          name: mockserver
                          port:
                            number: 1080
              - host: ${DEVSPACE_NAMESPACE}-grafana.${DEVSPACE_INGRESS_BASE_DOMAIN}
                http:
                  paths:
                    - path: /
                      backend:
                        service:
                          name: app-grafana
                          port:
                            number: 80
          networkPolicyDefault:
            ingress:
              allowCustomCidrs: true
              # Should be a comma separated list of CIDR blocks. To include
              # AWS ALB private CIDRs and optionally other custom CIDRs.
              # Example format: 10.0.0.0/16,192.168.0.1/24
              customCidrs: ${DEVSPACE_INGRESS_CIDRS}
          # deployment placement, standard helm stuff
          podAnnotations:
          nodeSelector:
          tolerations:
          affinity:
        ccipScriptsDeployment:
          enabled: true
          image: ${DEVSPACE_CCIP_SCRIPTS_IMAGE}
          oidcRoleARN: ${DEVSPACE_CCIP_SCRIPTS_OIDC_ROLE_ARN}
          outputBucketName: ${DEVSPACE_CCIP_SCRIPTS_OUTPUT_BUCKET_NAME}
  atlas-network-1-dev:
    updateImageTags: false
    namespace: ${DEVSPACE_NAMESPACE}
    helm:
      upgradeArgs: ["--timeout", "10m"]
      displayOutput: true
      chart:
        name: root
        path: ${MONITORING_NETWORK_PATH}
      valuesFiles:
        - ${MONITORING_NETWORK_1_VALUES_PATH}
      values:
        podSecurityContext:
          fsGroup: 999
  atlas-network-2-dev:
    updateImageTags: false
    namespace: ${DEVSPACE_NAMESPACE}
    helm:
      upgradeArgs: ["--timeout", "10m"]
      displayOutput: true
      chart:
        name: root
        path: ${MONITORING_NETWORK_PATH}
      valuesFiles:
        - ${MONITORING_NETWORK_2_VALUES_PATH}
      values:
        podSecurityContext:
          fsGroup: 999
  atlas-infra-dev:
    updateImageTags: false
    namespace: ${DEVSPACE_NAMESPACE}
    helm:
      upgradeArgs: ["--timeout", "10m"]
      displayOutput: true
      chart:
        name: root
        path: ${MONITORING_INFRA_PATH}
  atlas-network-1:
    updateImageTags: false
    namespace: ${DEVSPACE_NAMESPACE}
    helm:
      releaseName: atlas-network-1
      upgradeArgs: ["--timeout", "10m"]
      displayOutput: true
      chart:
        name: ${ATLAS_NETWORK_HELM_CHART_URI}
        version: "0.0.4"
      valuesFiles:
        - ${MONITORING_NETWORK_1_VALUES_PATH}
      values:
        podSecurityContext:
          fsGroup: 999
  atlas-network-2:
    updateImageTags: false
    namespace: ${DEVSPACE_NAMESPACE}
    helm:
      releaseName: atlas-network-2
      upgradeArgs: ["--timeout", "10m"]
      displayOutput: true
      chart:
        name: ${ATLAS_NETWORK_HELM_CHART_URI}
        version: "0.0.4"
      valuesFiles:
        - ${MONITORING_NETWORK_2_VALUES_PATH}
      values:
        podSecurityContext:
          fsGroup: 999
  atlas-infra:
    updateImageTags: false
    namespace: ${DEVSPACE_NAMESPACE}
    helm:
      upgradeArgs: ["--timeout", "10m"]
      displayOutput: true
      chart:
        name: ${ATLAS_INFRA_HELM_CHART_URI}
        version: "0.0.5"
profiles:
  - name: local-dev
    patches:
      # Remove the global overridesToml field.
      # This will be configured via a values file.
      - op: remove
        path: deployments.app.helm.values.chainlink-cluster.chainlink.global.overridesToml
      - op: add
        path: deployments.app.helm.valuesFiles
        value: ["./values-profiles/values-dev.yaml"]
      - op: replace
        path: deployments.app.helm.values.ccipScriptsDeployment.enabled
        value: false
